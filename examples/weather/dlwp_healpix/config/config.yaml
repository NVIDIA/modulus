defaults:
  - _self_
  - data: era5_hpx64_7var_6h_24h
  - model: hpx_unet
  - trainer: default

experiment_name: ${now:%Y-%m-%d}/${now:%H-%M-%S}
output_dir: outputs/${experiment_name}
checkpoint_name: null
load_weights_only: false
seed: 0

# Training specifications
batch_size: 32
learning_rate: 1e-3
num_workers: 8

# Distributed setup (multi GPU)
port: 29450
master_address: localhost

hydra:
  verbose: true
  run:
    dir: ${output_dir}