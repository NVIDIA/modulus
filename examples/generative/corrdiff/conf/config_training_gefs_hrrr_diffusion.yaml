# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
# SPDX-FileCopyrightText: All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

hydra:
    job:
          chdir: true
          name: gefs_hrrr_diffusion
    run:
          dir: ./output/${hydra:job.name}
    searchpath:
          - pkg://conf/base # Do not modify

# Base parameters for dataset, model, training, and validation
defaults:

    - dataset: gefs_hrrr
    # The dataset type for training.
    # Accepted values:
    #   `gefs_hrrr`: full GEFS-HRRR dataset for continental US.
    #   `hrrr_mini`: smaller HRRR dataset (continental US), for fast experiments.
    #   `cwb`: full CWB dataset for Taiwan.
    #   `custom`: user-defined dataset. Parameters need to be specified below.

    - model: lt_aware_patched_diffusion
    # The model type.
    # Accepted values:
    #     `regression`: a regression UNet for deterministic predictions
    #     `lt_aware_ce_regression`: similar to `regression` but with lead time
    #       conditioning
    #     `diffusion`: a diffusion UNet for residual predictions
    #     `patched_diffusion`: a more memory-efficient diffusion model
    #     `lt_aware_patched_diffusion`: similar to `patched_diffusion` but
    #       with lead time conditioning

    - model_size: normal
    # The model size configuration.
    # Accepted values:
    #     `normal`: normal model size
    #     `mini`: smaller model size for fast experiments

    - training: ${model}
    # The base training parameters. Determined by the model type.


# Dataset parameters. Used for `custom` dataset type.
# Modify or add below parameters that should be passed as argument to the
# user-defined dataset class.
dataset:
    data_path: /data
    # Path to .nc data file
    stats_path: /data/stats.json
    # Path to json stats file

model:
    scale_cond_input: true
    # If true, also scales the input conditioning. Set to True for backward
    # compatibility.

# Training parameters
training:
    hp:
        patch_shape_x: 448
        patch_shape_y: 448
        # Patch size. Patch training is used if these dimensions differ from
        # img_shape_x and img_shape_y.
        patch_num: 4
        # Number of patches from a single sample. Total number of patches is
            # patch_num * batch_size_global.
    io:
        regression_checkpoint_path: <path/to/checkpoint.mdlus>
        # Path to load the regression checkpoint

# Parameters for wandb logging
wanbd:
    mode: online
    # Logging mode. Accepted values: "offline", "online" or "disabled"
    key: <your_api_key>
    # You wandb API key
    project: <your_project_name>
    # Your wanb project name
    entity: <your_entity_name>
    # Name of your wandb enity
    name: <your_experiment_name>
    # Name of your experiment
    watch_model: true
    # Bool: if true, then wandb logs statistics about your model parameters