# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
# SPDX-FileCopyrightText: All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

defaults:
  - /logging/python: default
  - override hydra/job_logging: disabled  # We use rank-aware logger configuration instead.
  - _self_

hydra:
  run:
    dir: ${output}
  output_subdir: hydra  # Default is .hydra which causes files not being uploaded in W&B.

train:
  num_epochs: 100
  batch_size: 4
  save_interval: 1 # save model for every N'th epoch
  num_checkpoints: 2 # number of checkpoints to save
  time_limit: null
  resume: false
  print_interval: 200 # save image for every N'th train data
  dataloader:
    shuffle: true # can also specify the shuffle buffer size, e.g. shuffle_buffer_size: 100
    num_workers: 0
    pin_memory: true
  lr_scheduler_mode: epoch # epoch or iteration.

eval:
  loss: null
  run_eval_first: false
  interval: 5 # epoch
  batch_size: 1
  plot_interval: 20 # save image for every N'th test data
  print_interval: 20 # print every N'th test data
  dataloader:
    shuffle: false
    num_workers: 0
    pin_memory: true

device: cuda

seed: null

# The loss should be set in the experiment.
loss: ???

# The optimizer should be set in the experiment.
optimizer: ???

# Scheduler should be set in the experiment.
lr_scheduler: ???

amp:
  enabled: false
  autocast:
    dtype: torch.float16
  scaler:
    _target_: torch.cuda.amp.GradScaler
    enabled: ${..enabled}
  clip_grad: false
  grad_max_norm: 2.0

output: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

# Loggers.
log_dir: null
loggers:
  tensorboard: {}
  wandb:
    project_name: car-cfd
    run_name: default
    entity: physicsnemo # nvr-ai-algo
    group_name:
    mode: online

log_pointcloud: false # save pointclouds

# Signal handler
signal_handler:
  status_path: ${output}/status.txt
