{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction & Vision\n",
    "Welcome to this **prototype notebook**, which illustrates a **foundational workflow** for **Physics-AI** modeling, using **Darcy Flow** (and an **FNO** approach) as a **concrete example**. The goals of this notebook are **multi-faceted**:\n",
    "\n",
    "1. **Showcase a workflow** for **Physics-AI training** with **Darcy Flow** data, emphasizing how easily we can integrate **FNO** models in **NVIDIA Modulus** or similar frameworks.  \n",
    "2. **Demonstrate a general-purpose AutoML approach**—one that systematically searches for optimal **hyperparameters** (learning rate, channels, modes, etc.) across *any* PDE or neural operator.  \n",
    "3. **Preview Active Learning** as a complementary strategy to guide data acquisition based on model **uncertainty**. (In this notebook, I’ll outline how to do it; the *actual active learning code* is placed in a second notebook, [`darcy_active_learning.ipynb`](darcy_active_learning.ipynb).)\n",
    "\n",
    "Beyond these **current technical** accomplishments, this notebook also hints at **inspirational** next steps—extending from a **single PDE** toward a broad **Physics-AI solution** that includes:\n",
    "\n",
    "#### I. Technical (Software Engineering)\n",
    "- **Ontology-based data transformations**: A structured, automated pipeline for bridging different PDE data shapes (mesh ↔ grid ↔ point cloud). It reduces manual conversions and helps unify HPC outputs (e.g., AMReX) with ML-ready arrays.  \n",
    "- **Ontology engine**: A framework that **detects** dataset geometry (e.g., uniform grid vs. unstructured mesh) and picks the right operator or transformation step. This paves the way for “one-click” PDE model building, especially when integrated with AutoML.  \n",
    "- **AutoML for candidate selection**: Not just hyperparameters, but also *which* neural operator (FNO, AFNO, WNO, PINNs, etc.) is best for a given domain geometry or PDE. This accelerates experimentation by automatically ranking model architectures.  \n",
    "- **Advanced workflow, pipelines, and training**: Encompasses **HPC synergy** (ingesting large or partially refined HPC data), orchestrated pipelines (e.g., Kedro, Airflow), and **accelerated PDE surrogate training** (multi-GPU, distributed). Together, these let us efficiently handle time-evolving PDE snapshots and large-scale parameter sweeps in real engineering environments.\n",
    "\n",
    "#### II. Model & Physics Content\n",
    "- **Models: WNO, NUFNO, etc.**:\n",
    "  Beyond standard FNO, options like **Wavelet Neural Operator (WNO)** capture sharper local features via wavelet transforms, while **Non-Uniform FNO (NUFNO)** accommodates partial refinements or semi-structured domains. These advanced architectures can improve accuracy without a complete shift to graph-based methods.\n",
    "\n",
    "- **Customized operator designs**:\n",
    "  Domain-specific enhancements—e.g., a plasma-tailored FNO or specialized boundary treatments—boost performance on PDEs with unique constraints (sharp separatrices, anisotropy). This ensures surrogates match real-world physics more precisely than generic operators.\n",
    "\n",
    "- **Ensembles / partial refinement & local closures**:\n",
    "  In HPC settings with variable mesh refinement or subgrid phenomena, a hybrid approach (e.g., FNO + DiffusionNet) can handle global PDE patterns while focusing local operators on high-resolution patches. This preserves large-scale coverage and detail where it matters most.\n",
    "\n",
    "- **Multi-scale patterns**  \n",
    "  Many PDEs combine broad wave modes with fine-edged phenomena (e.g., subgrid turbulence). Leveraging wavelet-based or ensemble architectures means each scale can be tackled effectively—ensuring no critical features get lost.\n",
    "\n",
    "- **Multi-physics regimes**:\n",
    "  Real engineering tasks often blend multiple physics (e.g., fluid–structure interaction, electromagnetic–thermal coupling). By composing or extending neural operators for each sub-physics domain, we can solve coupled PDE sets under one pipeline.\n",
    "\n",
    "- **Physics-Informed Loss (added to current physics-informed architecture)**:\n",
    "  Incorporating PDE constraints directly into the training objective ensures surrogates adhere to known physics. This is invaluable for **inverse problem solving** (where data can be sparse) and for overall stability/robustness when extrapolating to new parameter regimes.\n",
    "\n",
    "#### III. Downstream Applications\n",
    "- **Inverse Problem Solving**:\n",
    "  Quickly invert PDE relationships to find **which input conditions** yield a desired output (e.g., *some configuration for a target outcome value*). This drastically reduces design-cycle times compared to iterative HPC solves.\n",
    "\n",
    "- **Optimization**:\n",
    "  Plug surrogates into parametric optimization loops (shape optimization, operational parameter tuning). The surrogate’s fast inference replaces expensive HPC calls at each iteration, speeding up design exploration.\n",
    "\n",
    "- **Deployment, HPC workflows, and MLOps**:\n",
    "  Once the model is trained, seamlessly **deploy** it alongside HPC codes for real-time PDE updates, controlling or monitoring processes. MLOps features (monitoring, versioning) ensure reliability, traceability, and easy model updates in production or research HPC clusters.\n",
    "\n",
    "I’m calling it a **“kick-off”** project because, even though it’s built around Darcy Flow and FNO, the underlying design can **readily scale**—both in terms of PDE complexity (multi-scale turbulence, advanced HPC data) and in terms of **workflow** (AutoML, HPC integration, interactive active learning, etc.). By adopting these modular components, we set the stage for a future in which **Physics-AI** model development becomes more automated, adaptable, and robust—serving a wide range of scientific and engineering challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [00_Generate_Data](#00_generate_data)  \n",
    "   - [00_01 Darcy Flow Simulation + Data Descriptor Creation](#00_01-darcy-flow-simulation--data-descriptor-creation)  \n",
    "     - Demonstrates **generating synthetic Darcy flow data** (via `Darcy2D`) and creating a **data descriptor**. This lays the groundwork for PDE data ingestion, transformations, and future AutoML usage.\n",
    "\n",
    "2. [01_Build_Surrogate_Model](#01_build_surrogate_model)  \n",
    "   - [01_00 AutoMLCandidateModelSelection](#01_00-automl-candidate-model-selection)\n",
    "     - **Motivation**: Showcases how we determine which PDE surrogate model(s) might work best given a dataset descriptor.  \n",
    "     - **01_00_01 Data Descriptor & Model Registry Initialization**  \n",
    "       - Loads the generated data descriptor, creates or loads a `ModelRegistry` with metadata for multiple models (FNO, AFNO, DiffusionNet, etc.).  \n",
    "     - **01_00_02 Candidate Model Selection & Validation**  \n",
    "       - Validates descriptor, applies selection logic (e.g., simple rules or advanced ranking), and saves the selected model(s) for downstream pipeline steps.\n",
    "\n",
    "   - [01_01 Data Loading and (Optional) Data Transformation](#01_01-data-loading-and-optional-data-transformation)  \n",
    "     - Covers loading raw `.pt` files or synthetic data, plus transformations like normalization or boundary labeling.  \n",
    "       - [01_01_01 LoadRawData](#01_01_01-loadrawdata)  \n",
    "         - Shows how `.pt` data is read, with minimal Exploratory Data Analysis (EDA).  \n",
    "       - [01_01_03 TransformRawData](#01_01_03-transformrawdata)  \n",
    "         - Applies any coordinate expansions, normalization, or shape fixes.  \n",
    "       - [01_01_04 Preprocessing](#01_01_04-preprocessing)  \n",
    "         - Optional steps for data quality checks or outlier removal.  \n",
    "       - [01_01_05 FeaturePreparation](#01_01_05-featurepreparation)  \n",
    "         - Final feature engineering, e.g., boundary-channel additions.\n",
    "\n",
    "   - [01_02 Model Definition](#01_02-model-definition)  \n",
    "     - **Implements** the PDE surrogate networks (e.g., `FNOWithDropout`, AFNO). Explains class architecture and relevant config fields.\n",
    "\n",
    "   - [01_03 Model Factory](#01_03-model-factory)  \n",
    "     - Demonstrates a single function `get_model(cfg)` that returns a chosen operator based on `model_name` in the config.\n",
    "\n",
    "   - [01_04 Configuring Hyperparameters](#01_04-configuring-hyperparameters)  \n",
    "     - Discusses reading or overriding hyperparams (Fourier modes, widths, learning rate, etc.) from `config.yaml`. Also references HPC or local usage.\n",
    "\n",
    "   - [01_05 Model Training Loop](#01_05-model-training-loop)  \n",
    "     - Outlines the core training logic: optimizer, loss, epoch iteration, logging (potentially with MLFlow).\n",
    "\n",
    "   - [01_06 Model Training Execution](#01_06-model-training-execution)  \n",
    "     - **Brings it together**: builds a `model`, obtains a `dataloader`, and runs the main training loop. For example:\n",
    "       ```python\n",
    "       model = get_model(cfg)\n",
    "       train_loader = get_darcy_data_loader(cfg)\n",
    "       final_val_loss = run_modulus_training_loop(cfg, model, train_loader)\n",
    "       ```\n",
    "     - Presents how we might do single-run or multi-model iteration.\n",
    "\n",
    "   - [01_07 AutoML and Hyperparameter Tuning](#01_07-automl-and-hyperparameter-tuning)  \n",
    "     - Demonstrates **Optuna** or similar libraries for PDE hyperparameter search (e.g., `modes`, `width`, `depth`, `lr`). Also covers multi-model tuning (FNO vs. AFNO).\n",
    "\n",
    "   - [01_08 Visualizing Performance and Results](#01_08-visualizing-performance-and-results)  \n",
    "     - Shows how to **plot** training/validation curves or produce PDE field comparisons (predicted vs. ground truth). Possibly lists best trials from AutoML.\n",
    "\n",
    "3. [Offline Active Learning (Short Overview)](#offline-active-learning-short-overview)\n",
    "   - **Note**: Active Learning steps (MC-Dropout for uncertain PDE samples) are covered in a separate notebook. We only summarize here.  \n",
    "   - [Active Learning Notebook](darcy_active_learning.ipynb) — The second file demonstrates:\n",
    "     1. Loading a **dropout-enabled** operator,\n",
    "     2. Running multiple forward passes for uncertainty,\n",
    "     3. Selecting top-K uncertain PDE inputs,\n",
    "     4. (Optionally) saving them for partial retraining or HPC PDE solves.\n",
    "\n",
    "> *If you only need to see the AL approach, jump directly to [Active Learning Notebook](darcy_active_learning.ipynb).* This first notebook focuses on data generation, model building, and AutoML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING) # logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "from darcy_automl_active_learning.path_utils import get_paths\n",
    "\n",
    "repo_root_path, darcy_project_root_path, config_file_path, data_dir_path, results_dir_path = get_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00_01 Darcy Flow Simulation & Data Descriptor Creation\n",
    "\n",
    "In this section, we will **generate synthetic Darcy flow data** using `Darcy2D` (part of the NVIDIA Modulus datapipe utilities) and **document** the resulting dataset via a standardized **data descriptor**. The data descriptor follows our **physics-AI data taxonomy**, ensuring we capture crucial fields like dimensionality, geometry type, uniformity, and so forth.\n",
    "\n",
    "1. **Generate Data**  \n",
    "   - We will create multiple `.pt` files containing the Darcy field samples (`permeability` and `darcy`), using the `Darcy2D` datapipe for 2D PDE generation.  \n",
    "   - These files are placed in the `data/00_Generate_Data/` folder.\n",
    "\n",
    "2. **Load Configuration**  \n",
    "   - We leverage a `config.yaml` that provides hyperparameters for data generation: resolution, batch size, normalizer values, etc.\n",
    "\n",
    "3. **Create a Data Descriptor**  \n",
    "   - After data generation, we write out a JSON file (e.g., `data_desc.json`) describing the dataset’s structure. This descriptor conforms to our **Core Taxonomy & Ontology** for PDE data. For a 2D uniform grid, we specify fields like `\"dimension\": 2`, `\"geometry_type\": \"grid\"`, `\"uniform\": true`, and the channel layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GenerateData] Initializing Darcy2D data loader...\n",
      "[GenerateData] Generating and saving 20 batch files to 'examples/cfd/darcy_autoML_active_learning/data/00_Generate_Data' ...\n",
      "Module modulus.datapipes.benchmarks.kernels.initialization 0f5b36a load on device 'cuda:0' took 48.97 ms  (cached)\n",
      "Module modulus.datapipes.benchmarks.kernels.utils 27df179 load on device 'cuda:0' took 301.55 ms  (cached)\n",
      "Module modulus.datapipes.benchmarks.kernels.finite_difference d7632e6 load on device 'cuda:0' took 154.55 ms  (cached)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# If you have Modulus installed:\n",
    "try:\n",
    "    from modulus.datapipes.benchmarks.darcy import Darcy2D\n",
    "except ImportError:\n",
    "    Darcy2D = None\n",
    "    print(\"[Warning] 'modulus.datapipes.benchmarks.darcy' not found. Please ensure NVIDIA Modulus is installed.\")\n",
    "\n",
    "SKIP_EXISTING = True  # True -> won't overwrite existing .pt files\n",
    "\n",
    "# 1) Load config from 'config_file' (path to your config.yaml)\n",
    "if not os.path.exists(config_file_path):\n",
    "    print(f\"[GenerateData] config.yaml not found at {config_file_path}; using fallback defaults.\")\n",
    "    cfg = OmegaConf.create({\n",
    "        \"normaliser\": {\n",
    "            \"permeability\": {\"mean\": 1.0, \"std_dev\": 0.5},\n",
    "            \"darcy\":       {\"mean\": 0.1, \"std_dev\": 0.05}\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"resolution\": 64,\n",
    "            \"batch_size\": 4,\n",
    "            \"max_pseudo_epochs\": 10,\n",
    "            \"pseudo_epoch_sample_size\": 512\n",
    "        }\n",
    "    })\n",
    "else:\n",
    "    cfg = OmegaConf.load(config_file_path)\n",
    "\n",
    "# 2) Construct normaliser info if config.yaml has mean/std for 'permeability' / 'darcy'\n",
    "norm_cfg = cfg.normaliser\n",
    "normaliser = {\n",
    "    \"permeability\": (norm_cfg.permeability.mean, norm_cfg.permeability.std_dev),\n",
    "    \"darcy\":       (norm_cfg.darcy.mean,       norm_cfg.darcy.std_dev),\n",
    "}\n",
    "\n",
    "# 3) Prepare an output directory under data_dir\n",
    "data_path = os.path.join(data_dir_path, \"00_Generate_Data\")\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "use_cuda_if_avail = True\n",
    "device = \"cuda\" if (use_cuda_if_avail and torch.cuda.is_available()) else \"cpu\"\n",
    "\n",
    "# 4) Try to instantiate Darcy2D (if Modulus is installed)\n",
    "if Darcy2D is None:\n",
    "    print(\"[GenerateData] Darcy2D not available. Skipping PDE generation or using fallback.\")\n",
    "else:\n",
    "    print(\"[GenerateData] Initializing Darcy2D data loader...\")\n",
    "    dataloader = Darcy2D(\n",
    "        resolution=cfg.training.resolution,\n",
    "        batch_size=cfg.training.batch_size,\n",
    "        normaliser=normaliser,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # 5) Determine how many batches to save\n",
    "    num_batches_to_save = cfg.training.batch_size * 5\n",
    "    print(f\"[GenerateData] Generating and saving {num_batches_to_save} batch files to '{data_path}' ...\")\n",
    "\n",
    "    for i in range(num_batches_to_save):\n",
    "        save_path = os.path.join(data_path, f\"darcy_batch_{i}.pt\")\n",
    "        if SKIP_EXISTING and os.path.exists(save_path):\n",
    "            print(f\"Skipping batch {i} -> file {save_path} already exists (SKIP_EXISTING=True).\")\n",
    "            continue\n",
    "\n",
    "        batch = next(iter(dataloader))\n",
    "        torch.save(batch, save_path)\n",
    "        perm_shape  = batch[\"permeability\"].shape\n",
    "        darcy_shape = batch[\"darcy\"].shape\n",
    "        print(f\"Saved batch {i} -> permeability {perm_shape}, darcy {darcy_shape}\")\n",
    "\n",
    "    print(\"[GenerateData] Data generation complete!\")\n",
    "\n",
    "# 6) Create a comprehensive data descriptor (2D uniform grid, 2 channels, etc.)\n",
    "data_descriptor = {\n",
    "    \"descriptor_name\": \"Darcy2D_Uniform_2Ch\",\n",
    "    \"data_structure\": {\n",
    "        \"dimension\": 2,\n",
    "        \"geometry_type\": \"grid\",\n",
    "        \"uniform\": True,\n",
    "        \"representation\": {\n",
    "            \"array_layout\": \"[N, H, W, C]\",\n",
    "            \"coordinate_mapping\": \"implicit uniform\",\n",
    "            \"coordinate_bounds\": {\n",
    "                \"x_min\": 0.0,\n",
    "                \"x_max\": 1.0,\n",
    "                \"y_min\": 0.0,\n",
    "                \"y_max\": 1.0\n",
    "            }\n",
    "        },\n",
    "        \"is_transient\": False,\n",
    "        \"boundary\": False,\n",
    "        \"boundary_info\": None,\n",
    "        \"cell_type\": None,\n",
    "        \"decimation\": False,\n",
    "        \"decimation_level\": None,\n",
    "        \"channels\": 2,\n",
    "        \"time_steps\": None,\n",
    "        \"adjacency\": False\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"pde_type\": \"Darcy\",\n",
    "        \"num_samples\": cfg.training.batch_size * 5,\n",
    "        \"description\": (\n",
    "            \"2D Darcy dataset with 2 channels (e.g. 'permeability' and 'darcy'), \"\n",
    "            \"generated via Modulus Darcy2D with uniform grid.\"\n",
    "        ),\n",
    "        \"source_script\": \"00_Generate_Data.ipynb\",\n",
    "        \"file_pattern\": \"darcy_batch_*.pt\",\n",
    "        \"notes\": \"Each .pt file stores a dict with keys 'permeability' & 'darcy'.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 7) Save the descriptor to JSON in the same directory\n",
    "data_desc_path = os.path.join(data_path, \"data_desc.json\")\n",
    "with open(data_desc_path, \"w\") as f:\n",
    "    json.dump(data_descriptor, f, indent=2)\n",
    "\n",
    "print(f\"[GenerateData] Wrote data descriptor to: {data_desc_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01_00 AutoML Candidate Model Selection\n",
    "\n",
    "Machine learning pipelines often involve a **model selection** phase, where we decide which model or models best fit a given dataset based on **data compatibility**, **user constraints**, and **desired outcomes** (e.g., accuracy vs. speed). In PDE-based workflows, this can become **challenging** because each **neural operator** or **graph-based surrogate** may expect different **geometry types** (mesh vs. grid), different channels or dimensionality, and so on.  \n",
    "\n",
    "In this section, we demonstrate a **simple** version of an **AutoML** or **candidate model selection** pipeline. We show how to:\n",
    "\n",
    "1. **Load** the data descriptor generated from the previous step (`00_Generate_Data`).  \n",
    "2. **Initialize** a `ModelRegistry` containing metadata for our six candidate models (e.g., FNO, AFNO, DiffusionNet).  \n",
    "3. **Create** a `CandidateModelSelector` or logic component that can pick which model(s) to recommend.  \n",
    "4. **Validate** that the dataset’s descriptor is coherent and meets minimal requirements.  \n",
    "5. **Select** candidate models (for demonstration, we pick FNO or whichever is compatible).  \n",
    "6. **Retrieve** the target data structure each candidate model expects.  \n",
    "7. **Save** the results—so future steps can build on them for data transformations, training pipelines, or hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01_00_01 Data Descriptor & Model Registry Initialization\n",
    "\n",
    "In this **first subsection**, we perform the **setup** needed to run the model selection routine:\n",
    "\n",
    "- **Load** the data descriptor from `data/00_Generate_Data/data_desc.json`, confirming it has the required **fields** (e.g., `dimension`, `geometry_type`, etc.).  \n",
    "- **Instantiate** our `ModelRegistry`, which knows about each candidate model’s **“accepted formats”**—like “2D uniform grid” for FNO or “3D unstructured mesh” for DiffusionNet. This registry can be extended later to incorporate **hyperparameters**, **training code references**, or **performance** metadata.  \n",
    "- (Optionally) **Preview** or **print** the loaded descriptor to ensure correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data descriptor from 'examples/cfd/darcy_autoML_active_learning/data/00_Generate_Data/data_desc.json'...\n",
      "[AutoML] Data descriptor loaded successfully. Domain Data Structures:\n",
      "  - 'descriptor_name': Darcy2D_Uniform_2Ch\n",
      "[AutoML] ModelRegistry initialized. Available models:\n",
      "  - AFNO\n",
      "  - DiffusionNet\n",
      "  - FNOWithDropout\n",
      "  - FNO\n",
      "  - GraphCast\n",
      "  - NuFNO\n",
      "  - WNO\n",
      "[AutoML] Data descriptor is valid.\n",
      "[AutoML] Selected candidates: [('FNOWithDropout', 'candidate0'), ('AFNO', 'candidate1')]\n",
      "[AutoML] For model 'FNOWithDropout' (key='candidate0'), the required data structure is:\n",
      "[{'dimension': [2, 3], 'geometry_type': ['grid'], 'representations': [{'representation_name': 'uniform_grid', 'uniform': True, 'is_voxel_grid': False, 'is_transient_supported': False, 'channels_min': 1, 'channels_max': None, 'boundary_required': False, 'mesh_type': None, 'notes': 'Same shape requirements as vanilla FNO (e.g. [N, C, H, W] for 2D).'}]}]\n",
      "[AutoML] For model 'AFNO' (key='candidate1'), the required data structure is:\n",
      "[{'dimension': [2, 3], 'geometry_type': ['grid'], 'representations': [{'representation_name': 'uniform_grid', 'uniform': True, 'is_voxel_grid': False, 'channels_min': 1, 'channels_max': None, 'boundary_required': False, 'is_transient_supported': True, 'notes': 'Similar data layout to FNO: [N, C, H, W] or [N, C, D, H, W].'}]}]\n",
      "[CandidateModelSelector] Saved 2 candidates to: examples/cfd/darcy_autoML_active_learning/data/01_00_AutoMLCandidateModelSelection/chosen_candidates.json\n",
      "[AutoMLCandidateModelSelection] Results saved to: examples/cfd/darcy_autoML_active_learning/data/01_00_AutoMLCandidateModelSelection/chosen_candidates.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from darcy_automl_active_learning.model_registry.model_registry import ModelRegistry\n",
    "from darcy_automl_active_learning.model_selection.candidate_selector import CandidateModelSelector\n",
    "from darcy_automl_active_learning.model_selection.selection_strategies import SimpleSelectionStrategy\n",
    "# If you have a data descriptor utility:\n",
    "# from darcy_automl_active_learning.data_descriptor.data_descriptor_utils import load_data_descriptor\n",
    "\n",
    "# 1) Identify the path to the data descriptor\n",
    "data_desc_path = f\"{data_dir_path}/00_Generate_Data/data_desc.json\"\n",
    "print(f\"Loading data descriptor from '{data_desc_path}'...\")\n",
    "\n",
    "# Optionally, load the descriptor directly if you want to do some pre-check:\n",
    "with open(data_desc_path, \"r\") as f:\n",
    "    data_desc = json.load(f)\n",
    "print(\"[AutoML] Data descriptor loaded successfully. Domain Data Structures:\")\n",
    "print(f\"  - 'descriptor_name': {data_desc.get('descriptor_name')}\")\n",
    "\n",
    "# 2) Initialize the ModelRegistry (defaults to the 6-7 candidate models)\n",
    "registry = ModelRegistry()\n",
    "print(\"[AutoML] ModelRegistry initialized. Available models:\")\n",
    "for m in registry.list_models():\n",
    "    print(f\"  - {m}\")\n",
    "\n",
    "# 3) Create our CandidateModelSelector using a strategy\n",
    "#    Here, we use a \"SimpleSelectionStrategy\" that always picks FNO, just for demonstration.\n",
    "strategy = SimpleSelectionStrategy()\n",
    "candidate_selector = CandidateModelSelector(\n",
    "    model_registry=registry,\n",
    "    selection_strategy=strategy\n",
    ")\n",
    "\n",
    "# 4) Validate the data descriptor\n",
    "#    (If you have a custom load/validate function, call it here.\n",
    "#     Or you can rely on candidate_selector internally.)\n",
    "is_valid = candidate_selector.validate_data_descriptor(data_desc_path)\n",
    "if not is_valid:\n",
    "    raise ValueError(\"[AutoML] Data descriptor validation failed. Please fix the descriptor.\")\n",
    "\n",
    "print(\"[AutoML] Data descriptor is valid.\")\n",
    "\n",
    "# 5) Perform candidate model selection\n",
    "selected_candidates = candidate_selector.automl_candidate_model_selection(data_desc_path)\n",
    "print(\"[AutoML] Selected candidates:\", selected_candidates)\n",
    "\n",
    "# 6) For each selected model, retrieve the required data structure\n",
    "for (model_name, candidate_key) in selected_candidates:\n",
    "    data_struct = candidate_selector.get_required_data_structure(model_name)\n",
    "    print(f\"[AutoML] For model '{model_name}' (key='{candidate_key}'), \"\n",
    "          f\"the required data structure is:\\n{data_struct}\")\n",
    "\n",
    "# 7) Save the chosen candidates to JSON so that later steps know which model(s) we plan to train\n",
    "output_folder = f\"{data_dir_path}/01_00_AutoMLCandidateModelSelection\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "save_path = candidate_selector.save_candidate_models(selected_candidates, output_folder)\n",
    "print(f\"[AutoMLCandidateModelSelection] Results saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01_00_02 Candidate Model Selection & Validation\n",
    "\n",
    "In this **second subsection**, we apply the actual **selection** routine:\n",
    "\n",
    "1. **Validate** the data descriptor, ensuring it meets minimal fields (e.g. `dimension`, `geometry_type`) and that it’s consistent with the PDE problem.\n",
    "2. **Apply** the selection logic, which might be as simple as “Pick FNO if the data is 2D–3D uniform,” or as complex as an **algorithm** that ranks models by performance, speed, or hyperparameter constraints.\n",
    "3. For each **recommended** model, we fetch the **target data structure** (e.g. `{\"dimension\": [2,3], \"uniform\": true, ...}`) so we know what transformations might be needed.\n",
    "4. **Store** or **save** the chosen candidates (and any relevant metadata) so we can retrieve them later when performing data transformations, training, or hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Candidate: candidate0] Model: FNOWithDropout\n",
      " - Required data structure: [{'dimension': [2, 3], 'geometry_type': ['grid'], 'representations': [{'representation_name': 'uniform_grid', 'uniform': True, 'is_voxel_grid': False, 'is_transient_supported': False, 'channels_min': 1, 'channels_max': None, 'boundary_required': False, 'mesh_type': None, 'notes': 'Same shape requirements as vanilla FNO (e.g. [N, C, H, W] for 2D).'}]}]\n",
      " - Proposed transformation plan: {'model_name': 'FNOWithDropout', 'stages': [{'stage_name': '01_01_01_LoadRawData', 'transform_ops': [{'method': 'copy_only', 'params': {'source_folder': '00_Generate_Data', 'dest_folder': '01_01_LoadRawData', 'subfolder_source': 'candidate0', 'subfolder_dest': 'candidate0', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}, {'stage_name': '01_01_03_TransformRawData', 'transform_ops': [{'method': 'copy_only', 'params': {'source_folder': '01_01_LoadRawData', 'dest_folder': '01_01_03_TransformRawData', 'subfolder_source': 'candidate0', 'subfolder_dest': 'candidate0', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}, {'stage_name': '01_01_04_Preprocessing', 'transform_ops': [{'method': 'copy_only', 'params': {'source_folder': '01_01_03_TransformRawData', 'dest_folder': '01_01_04_Preprocessing', 'subfolder_source': 'candidate0', 'subfolder_dest': 'candidate0', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}, {'stage_name': '01_01_05_FeaturePreparation', 'transform_ops': [{'method': 'copy_only', 'params': {'source_folder': '01_01_04_Preprocessing', 'dest_folder': '01_01_05_FeaturePreparation', 'subfolder_source': 'candidate0', 'subfolder_dest': 'candidate0', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}]} \n",
      "\n",
      "[Candidate: candidate1] Model: AFNO\n",
      " - Required data structure: [{'dimension': [2, 3], 'geometry_type': ['grid'], 'representations': [{'representation_name': 'uniform_grid', 'uniform': True, 'is_voxel_grid': False, 'channels_min': 1, 'channels_max': None, 'boundary_required': False, 'is_transient_supported': True, 'notes': 'Similar data layout to FNO: [N, C, H, W] or [N, C, D, H, W].'}]}]\n",
      " - Proposed transformation plan: {'model_name': 'AFNO', 'stages': [{'stage_name': '01_01_01_LoadRawData', 'transform_ops': [{'method': 'copy_only', 'params': {'source_folder': '00_Generate_Data', 'dest_folder': '01_01_LoadRawData', 'subfolder_source': 'candidate1', 'subfolder_dest': 'candidate1', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}, {'stage_name': '01_01_03_TransformRawData', 'transform_ops': [{'method': 'copy_only', 'params': {'source_folder': '01_01_LoadRawData', 'dest_folder': '01_01_03_TransformRawData', 'subfolder_source': 'candidate1', 'subfolder_dest': 'candidate1', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}, {'stage_name': '01_01_04_Preprocessing', 'transform_ops': [{'method': 'copy_only', 'params': {'source_folder': '01_01_03_TransformRawData', 'dest_folder': '01_01_04_Preprocessing', 'subfolder_source': 'candidate1', 'subfolder_dest': 'candidate1', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}, {'stage_name': '01_01_05_FeaturePreparation', 'transform_ops': [{'method': 'copy_only', 'params': {'source_folder': '01_01_04_Preprocessing', 'dest_folder': '01_01_05_FeaturePreparation', 'subfolder_source': 'candidate1', 'subfolder_dest': 'candidate1', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}]} \n",
      "\n",
      "[Info] Transformation plans saved to examples/cfd/darcy_autoML_active_learning/data/01_01_DataTransformationPlan/transformation_plans.json.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from darcy_automl_active_learning.model_selection.candidate_selector import CandidateModelSelector\n",
    "from darcy_automl_active_learning.ontology.ontology_engine import OntologyEngine\n",
    "\n",
    "########################\n",
    "# 0) READ INPUTS\n",
    "########################\n",
    "\n",
    "# Load the chosen candidates from the previous step (01_00 AutoMLCandidateModelSelection).\n",
    "candidates_path = os.path.join(data_dir_path, \"01_00_AutoMLCandidateModelSelection\", \"chosen_candidates.json\")\n",
    "with open(candidates_path, \"r\") as f:\n",
    "    selected_candidates = json.load(f)\n",
    "# Example: selected_candidates = [[\"FNO\", \"candidate0\"], [\"DiffusionNet\", \"candidate1\"], ...]\n",
    "\n",
    "# Load the data descriptor (the \"source\" data structure).\n",
    "data_desc_path = os.path.join(data_dir_path, \"00_Generate_Data\", \"data_desc.json\")\n",
    "with open(data_desc_path, \"r\") as f:\n",
    "    data_desc = json.load(f)\n",
    "\n",
    "########################\n",
    "# 1) INITIALIZE CLASSES\n",
    "########################\n",
    "ontology_engine = OntologyEngine()\n",
    "candidate_selector = CandidateModelSelector(\n",
    "    model_registry=registry,\n",
    "    selection_strategy=strategy\n",
    ")\n",
    "\n",
    "########################\n",
    "# 2) GENERATE TRANSFORMATION PLANS\n",
    "########################\n",
    "\n",
    "all_candidates_plans = {}\n",
    "\n",
    "for (model_name, candidate_key) in selected_candidates:\n",
    "    # Query the model registry/selector to get the \"desired/required data structure\"\n",
    "    target_data_struct = candidate_selector.get_required_data_structure(model_name)\n",
    "    \n",
    "    # Ask the ontology engine what transformations are needed\n",
    "    transformation_plan = ontology_engine.suggest_transformations(\n",
    "        source_data_desc=data_desc[\"data_structure\"],\n",
    "        target_data_requirements=target_data_struct,\n",
    "        model_name=model_name,\n",
    "        candidate_key=candidate_key,\n",
    "        data_dir_path=data_dir_path\n",
    "    )\n",
    "\n",
    "    print(f\"[Candidate: {candidate_key}] Model: {model_name}\")\n",
    "    print(\" - Required data structure:\", target_data_struct)\n",
    "    print(\" - Proposed transformation plan:\", transformation_plan, \"\\n\")\n",
    "    \n",
    "    # Store the plan in a dictionary for future steps\n",
    "    all_candidates_plans[candidate_key] = {\n",
    "        \"model_name\": model_name,\n",
    "        \"plan\": transformation_plan\n",
    "    }\n",
    "\n",
    "# Optionally, save these plans to JSON so other notebook sections can load them\n",
    "plans_output_path = os.path.join(data_dir_path, \"01_01_DataTransformationPlan\", \"transformation_plans.json\")\n",
    "os.makedirs(os.path.dirname(plans_output_path), exist_ok=True)\n",
    "\n",
    "with open(plans_output_path, \"w\") as f:\n",
    "    json.dump(all_candidates_plans, f, indent=2)\n",
    "\n",
    "print(f\"[Info] Transformation plans saved to {plans_output_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 01_01 Data Loading and (Optional) Data Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01_01_01 LoadRawData\n",
    "\n",
    "In this subsection, we handle the **initial import** of raw `.pt` files generated during our **“00_Generate_Data”** step. These files typically contain PDE fields (e.g., **`permeability`**, **`darcy`**) that we’ll eventually feed into one or more candidate models. Specifically, we aim to:\n",
    "\n",
    "1. **Copy** the `.pt` files from `data/00_Generate_Data/` into a new folder, `data/01_01_LoadRawData/`.  \n",
    "2. **Preserve** the existing data descriptor (`data_desc.json`), ensuring we maintain consistent metadata on dimensions, geometry types, channels, etc.  \n",
    "3. Optionally perform minimal **exploratory data analysis (EDA)**—for instance, loading a sample `.pt` file and checking array shapes or key names.\n",
    "\n",
    "Why a separate **LoadRawData** step? By isolating this phase, we keep our pipeline **modular**: each section (loading, transforming, preprocessing, feature engineering) has its own folder and minimal concerns. This structure scales well to more complex PDE workflows or HPC environments, where multiple transformations or domain-specific checks might be added later.\n",
    "\n",
    "We’ll also demonstrate how we can integrate **transformation plans**—particularly the “01_01_01_LoadRawData” stage from our `transformation_plans.json`—to orchestrate these copy/EDA operations consistently. In a real production setting, you might expand this step to include **additional** data integrity checks (e.g., verifying file counts, ensuring no missing `.pt` or descriptor file), or HPC scheduling logic. For now, our **copy** operation and light EDA illustrate how to set a clear foundation for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoadRawData] Loaded transformation plans from examples/cfd/darcy_autoML_active_learning/data/01_01_DataTransformationPlan/transformation_plans.json.\n",
      "Candidate keys found: ['candidate0', 'candidate1']\n",
      "\n",
      "[LoadRawData] Processing candidate 'candidate0' for model 'FNOWithDropout'\n",
      "    -> Invoking 'copy_only' with params: {'source_folder': '00_Generate_Data', 'dest_folder': '01_01_LoadRawData', 'subfolder_source': 'candidate0', 'subfolder_dest': 'candidate0', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}\n",
      "[OntologyTransformationEngine] COPY_ONLY done: examples/cfd/darcy_autoML_active_learning/data/00_Generate_Data/candidate0 -> examples/cfd/darcy_autoML_active_learning/data/01_01_LoadRawData/candidate0\n",
      "\n",
      "[LoadRawData] Processing candidate 'candidate1' for model 'AFNO'\n",
      "    -> Invoking 'copy_only' with params: {'source_folder': '00_Generate_Data', 'dest_folder': '01_01_LoadRawData', 'subfolder_source': 'candidate1', 'subfolder_dest': 'candidate1', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}\n",
      "[OntologyTransformationEngine] COPY_ONLY done: examples/cfd/darcy_autoML_active_learning/data/00_Generate_Data/candidate1 -> examples/cfd/darcy_autoML_active_learning/data/01_01_LoadRawData/candidate1\n",
      "\n",
      "[LoadRawData] All candidates processed for stage '01_01_01_LoadRawData'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from darcy_automl_active_learning.ontology.ontology_transformation_engine import OntologyTransformationEngine\n",
    "\n",
    "# 1) Path to the transformation plans (produced by OntologyEngine in an earlier step).\n",
    "plans_json_path = os.path.join(data_dir_path, \"01_01_DataTransformationPlan\", \"transformation_plans.json\")\n",
    "\n",
    "if not os.path.exists(plans_json_path):\n",
    "    raise FileNotFoundError(f\"[LoadRawData] Cannot find transformation plans at {plans_json_path}\")\n",
    "\n",
    "# 2) Load the transformation plans\n",
    "with open(plans_json_path, \"r\") as f:\n",
    "    all_candidates_plans = json.load(f)\n",
    "\n",
    "print(f\"[LoadRawData] Loaded transformation plans from {plans_json_path}.\")\n",
    "print(\"Candidate keys found:\", list(all_candidates_plans.keys()))\n",
    "\n",
    "# Example structure of all_candidates_plans (dictionary):\n",
    "# {\n",
    "#   \"candidate0\": { \"model_name\": \"FNOWithDropout\", \"plan\": {...} },\n",
    "#   \"candidate1\": { \"model_name\": \"AFNO\",          \"plan\": {...} },\n",
    "#    ...\n",
    "# }\n",
    "\n",
    "# 3) Instantiate our transformation engine\n",
    "trans_engine = OntologyTransformationEngine()\n",
    "\n",
    "# 4) We'll iterate through each candidate, find the stage \"01_01_01_LoadRawData\",\n",
    "#    and execute its transform_ops in order.\n",
    "for candidate_key, plan_info in all_candidates_plans.items():\n",
    "    # plan_info might look like:\n",
    "    # {\n",
    "    #   \"model_name\": \"FNOWithDropout\",\n",
    "    #   \"plan\": {\n",
    "    #       \"model_name\": \"FNOWithDropout\",\n",
    "    #       \"stages\": [\n",
    "    #         { \n",
    "    #           \"stage_name\": \"01_01_01_LoadRawData\",\n",
    "    #           \"transform_ops\": [ { \"method\": \"copy_only\", \"params\": {...} }, ... ]\n",
    "    #         },\n",
    "    #         ...\n",
    "    #       ]\n",
    "    #   }\n",
    "    # }\n",
    "    model_name = plan_info[\"model_name\"]\n",
    "    plan_dict  = plan_info[\"plan\"]\n",
    "\n",
    "    print(f\"\\n[LoadRawData] Processing candidate '{candidate_key}' for model '{model_name}'\")\n",
    "\n",
    "    # 4a) Retrieve the \"stages\" from plan_dict\n",
    "    stages = plan_dict.get(\"stages\", [])\n",
    "    # 4b) Filter for the stage we want -> \"01_01_01_LoadRawData\"\n",
    "    loadraw_stage = next(\n",
    "        (st for st in stages if st.get(\"stage_name\") == \"01_01_01_LoadRawData\"),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if loadraw_stage is None:\n",
    "        print(f\"    -> No '01_01_01_LoadRawData' stage found for candidate '{candidate_key}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 4c) Execute each transform_op\n",
    "    transform_ops = loadraw_stage.get(\"transform_ops\", [])\n",
    "    for op in transform_ops:\n",
    "        method_name = op[\"method\"]\n",
    "        params      = op[\"params\"]\n",
    "\n",
    "        print(f\"    -> Invoking '{method_name}' with params: {params}\")\n",
    "        # We'll dispatch to the transformation engine methods\n",
    "        if hasattr(trans_engine, method_name):\n",
    "            method = getattr(trans_engine, method_name)\n",
    "            method(**params)  # e.g. copy_only(source_folder, dest_folder)\n",
    "        else:\n",
    "            print(f\"    -> [Warning] Transformation method '{method_name}' not found. Skipped.\")\n",
    "\n",
    "print(\"\\n[LoadRawData] All candidates processed for stage '01_01_01_LoadRawData'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### 01_01_03 TransformRawData\n",
    "\n",
    "In this section, we apply (or simulate) **data transformations** needed by each **candidate model**. Recall that the previous step selected one or more target architectures (e.g., `\"FNO\"`, `\"AFNO\"`, `\"DiffusionNet\"`) and assigned them labels (`\"candidate0\"`, `\"candidate1\"`, etc.). Here, each candidate’s data flows from **`01_01_LoadRawData`** into a **new** subfolder—for instance, `data/01_01_03_TransformRawData/candidate0/`.\n",
    "\n",
    "1. **Copy** the `.pt` files from the “LoadRawData” folder.  \n",
    "2. **Transform** them per model requirements (if necessary).\n",
    "\n",
    "> **Why Transform?**  \n",
    "> Different models impose distinct constraints on the dataset’s **geometry**, **resolution**, or **channels**. From an HPC or PDE perspective, transformations ensure the raw data aligns with each model’s assumptions—such as **spectral operators** needing uniform spacing or **mesh-based operators** expecting unstructured vertex/face data.\n",
    "\n",
    "> **Possible Transformations** might include:\n",
    "> - **TRANSFORM_MESH_TO_GRID**:  \n",
    ">   Convert unstructured mesh data to a uniform grid—necessary if you want to feed a domain with irregular elements into a **Fourier** or **wavelet** operator that performs global transforms along regular axes. This can involve interpolation or resampling of original nodal values.  \n",
    ">\n",
    "> - **TRANSFORM_DECIMATE_MESH**:  \n",
    ">   Downsample or reduce vertex count for large HPC-generated meshes. This is often needed if memory constraints or real-time performance requires smaller data sets. Decimation should preserve key PDE features or boundaries without losing critical geometry detail.  \n",
    ">\n",
    "> - **TRANSFORM_REGRID_DATA**:  \n",
    ">   Change resolution from, say, 128×128 to 64×64, matching a model’s input dimension or training memory budget. This is especially relevant for **FNO/AFNO** if your PDE solver originally output very high resolution.  \n",
    ">\n",
    "> - **TRANSFORM_ADD_BOUNDARY_CHANNEL**:  \n",
    ">   Insert an extra channel labeling boundary indices, inlet/outlet regions, or domain interfaces. Many PDE surrogates benefit from explicitly differentiating boundary conditions.  \n",
    ">\n",
    "> - **TRANSFORM_COORDINATE_MAPPING**:  \n",
    ">   Adjust coordinate references (e.g., non-uniform → uniform) or embed extra coordinate fields (e.g., adding `(x, y)` grids as input channels). Useful for **PINNs** or operator-learning methods that rely on positional encodings.  \n",
    ">\n",
    "> - **TRANSFORM_NORMALIZE_TENSORS**:  \n",
    ">   Scale PDE fields to a standard range or distribution (e.g., zero mean, unit variance). This can stabilize training by preventing large differences in scales across multiple PDE variables (e.g., velocity vs. pressure).  \n",
    ">\n",
    "> - **TRANSFORM_TIME_SUBSAMPLING** (if transient data):  \n",
    ">   Select or downsample time steps from a high-frequency simulation if your surrogate only needs coarse temporal resolution.\n",
    "\n",
    "> **Minimal or Custom**  \n",
    "> Sometimes, no transformation is needed if the dataset already matches the model’s expected shape (e.g., a 2D uniform grid for FNO). In other scenarios—especially bridging drastically different data formats—transforms can be **extensive** (e.g., partial **voxelization** or complex manifold parameterization for unstructured surfaces).\n",
    "\n",
    "**Implementation Outline**  \n",
    "1. **Identify** the selected models and their subfolders (e.g., `\"candidate0\"` for FNO).  \n",
    "2. **Gather** relevant transformations from a “transformation plan” (possibly stored in JSON or a Python object).  \n",
    "3. **Apply** the transformations in sequence to each `.pt` file (or geometry file) from the previous step:\n",
    "   - Each step modifies shapes, channels, geometry format, or resolution.  \n",
    "   - If no transform is required, the script simply copies the data.  \n",
    "4. **Save** the result in `01_01_03_TransformRawData/candidateX/` with an **updated `data_desc.json`** if the geometry or channels changed. That descriptor now reflects the new data layout (e.g., from `dimension=3, geometry_type=\"mesh\"` to `dimension=2, geometry_type=\"grid\"`).\n",
    "\n",
    "By isolating each candidate’s transformed data, we keep the pipeline modular, ensuring that subsequent **Preprocessing** or **FeaturePreparation** steps can be tailored per model. For demonstration, we’ll parse a JSON file listing our chosen candidates (e.g., `[[\"FNO\", \"candidate0\"], ...]`) and apply a minimal transform (or copying) to confirm the pipeline structure. In a production scenario, you might incorporate advanced geometry libraries (e.g., PyVista, VTK) or PDE-aware boundary labeling at this stage, especially in HPC contexts where domain complexity is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TransformRawData] Loaded transformation plans from examples/cfd/darcy_autoML_active_learning/data/01_01_DataTransformationPlan/transformation_plans.json.\n",
      "Candidate keys found: ['candidate0', 'candidate1']\n",
      "\n",
      "[TransformRawData] Processing candidate 'candidate0' for model 'FNOWithDropout'\n",
      "    -> Invoking 'copy_only' with params: {'source_folder': '01_01_LoadRawData', 'dest_folder': '01_01_03_TransformRawData', 'subfolder_source': 'candidate0', 'subfolder_dest': 'candidate0', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}\n",
      "[OntologyTransformationEngine] COPY_ONLY done: examples/cfd/darcy_autoML_active_learning/data/01_01_LoadRawData/candidate0 -> examples/cfd/darcy_autoML_active_learning/data/01_01_03_TransformRawData/candidate0\n",
      "\n",
      "[TransformRawData] Processing candidate 'candidate1' for model 'AFNO'\n",
      "    -> Invoking 'copy_only' with params: {'source_folder': '01_01_LoadRawData', 'dest_folder': '01_01_03_TransformRawData', 'subfolder_source': 'candidate1', 'subfolder_dest': 'candidate1', 'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}\n",
      "[OntologyTransformationEngine] COPY_ONLY done: examples/cfd/darcy_autoML_active_learning/data/01_01_LoadRawData/candidate1 -> examples/cfd/darcy_autoML_active_learning/data/01_01_03_TransformRawData/candidate1\n",
      "\n",
      "[TransformRawData] All candidates processed for stage '01_01_03_TransformRawData'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from darcy_automl_active_learning.ontology.ontology_transformation_engine import OntologyTransformationEngine\n",
    "\n",
    "# 1) Path to the transformation plans (produced by OntologyEngine in an earlier step).\n",
    "plans_json_path = os.path.join(data_dir_path, \"01_01_DataTransformationPlan\", \"transformation_plans.json\")\n",
    "\n",
    "if not os.path.exists(plans_json_path):\n",
    "    raise FileNotFoundError(f\"[TransformRawData] Cannot find transformation plans at {plans_json_path}\")\n",
    "\n",
    "# 2) Load the transformation plans\n",
    "with open(plans_json_path, \"r\") as f:\n",
    "    all_candidates_plans = json.load(f)\n",
    "\n",
    "print(f\"[TransformRawData] Loaded transformation plans from {plans_json_path}.\")\n",
    "print(\"Candidate keys found:\", list(all_candidates_plans.keys()))\n",
    "\n",
    "# Example structure of all_candidates_plans (dictionary):\n",
    "# {\n",
    "#   \"candidate0\": { \"model_name\": \"FNOWithDropout\", \"plan\": {...} },\n",
    "#   \"candidate1\": { \"model_name\": \"AFNO\",          \"plan\": {...} },\n",
    "#   ...\n",
    "# }\n",
    "\n",
    "# 3) Instantiate our transformation engine\n",
    "trans_engine = OntologyTransformationEngine()\n",
    "\n",
    "# 4) We'll iterate through each candidate, find the stage \"01_01_03_TransformRawData\",\n",
    "#    and execute its transform_ops in order.\n",
    "for candidate_key, plan_info in all_candidates_plans.items():\n",
    "    # plan_info might look like:\n",
    "    # {\n",
    "    #   \"model_name\": \"FNOWithDropout\",\n",
    "    #   \"plan\": {\n",
    "    #       \"model_name\": \"FNOWithDropout\",\n",
    "    #       \"stages\": [\n",
    "    #         {\n",
    "    #           \"stage_name\": \"01_01_01_LoadRawData\",\n",
    "    #           \"transform_ops\": [...]\n",
    "    #         },\n",
    "    #         {\n",
    "    #           \"stage_name\": \"01_01_03_TransformRawData\",\n",
    "    #           \"transform_ops\": [...]\n",
    "    #         },\n",
    "    #         ...\n",
    "    #       ]\n",
    "    #   }\n",
    "    # }\n",
    "    model_name = plan_info[\"model_name\"]\n",
    "    plan_dict  = plan_info[\"plan\"]\n",
    "\n",
    "    print(f\"\\n[TransformRawData] Processing candidate '{candidate_key}' for model '{model_name}'\")\n",
    "\n",
    "    # 4a) Retrieve the list of stages from plan_dict\n",
    "    stages = plan_dict.get(\"stages\", [])\n",
    "\n",
    "    # 4b) Look for the stage named \"01_01_03_TransformRawData\"\n",
    "    transformraw_stage = next(\n",
    "        (st for st in stages if st.get(\"stage_name\") == \"01_01_03_TransformRawData\"),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if transformraw_stage is None:\n",
    "        print(f\"    -> No '01_01_03_TransformRawData' stage found for candidate '{candidate_key}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 4c) Execute each transform_op in that stage\n",
    "    transform_ops = transformraw_stage.get(\"transform_ops\", [])\n",
    "    for op in transform_ops:\n",
    "        method_name = op[\"method\"]\n",
    "        params      = op[\"params\"]\n",
    "\n",
    "        # Log the operation\n",
    "        print(f\"    -> Invoking '{method_name}' with params: {params}\")\n",
    "\n",
    "        # Dispatch to the transformation engine methods\n",
    "        if hasattr(trans_engine, method_name):\n",
    "            method = getattr(trans_engine, method_name)\n",
    "            method(**params)  # e.g., copy_only(source_folder, dest_folder)\n",
    "        else:\n",
    "            print(f\"    -> [Warning] Transformation method '{method_name}' not found. Skipped.\")\n",
    "\n",
    "print(\"\\n[TransformRawData] All candidates processed for stage '01_01_03_TransformRawData'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### 01_01_04 Preprocessing\n",
    "\n",
    "Even after **data transformations** (e.g., re-gridding or mesh decimation), **real-world PDE workflows** frequently require **additional** refinement before final training. This **preprocessing** ensures the dataset is consistently formatted, free of corruption, and enriched with any domain-specific metadata. Common operations might include:\n",
    "\n",
    "- **Geometry Augmentation**  \n",
    "  Performing random translations, rotations, or domain cropping to enhance model robustness and generalization.  \n",
    "\n",
    "- **Cleaning & Filtering**  \n",
    "  - **`PREPROC_REMOVE_OUTLIERS`**: Identifying and removing aberrant data points (e.g., extremely large velocities or pressures that arise from solver instabilities).  \n",
    "  - **`PREPROC_DETECT_REPLACE_NANS`**: Automatically detecting `NaN` or infinite values and replacing them with defaults (e.g., zeros) or discarding those samples.  \n",
    "  - **`PREPROC_FILTER_INCOMPLETE_SAMPLES`**: Skipping data entries where certain channels or geometry components are missing (e.g., partial PDE fields).  \n",
    "\n",
    "- **Domain-Specific Preprocessing**  \n",
    "  - **`PREPROC_LOG_STATS`**: Logging basic statistics (mean, std, min/max) per channel or boundary region for QA/QC.  \n",
    "  - **`PREPROC_ADD_BOUNDARY_LABELS`**: Adding specialized boundary or interface labels, if not handled in the transform phase.  \n",
    "  - **`PREPROC_ADD_CUSTOM_COORDS`**: Incorporating advanced parameterizations (e.g., polar/spherical coordinates for circular or spherical domains).  \n",
    "  - **`PREPROC_MULTI_PHYSICS_COMBINE`**: Merging multiple PDE fields (e.g., fluid + thermal data) into a unified feature map.\n",
    "\n",
    "---\n",
    "\n",
    "In our **prototype** pipeline, we **simplify** preprocessing to minimal or **no** extra modifications. We essentially:\n",
    "\n",
    "1. **Copy** each candidate’s transformed data files into a **`01_01_04_Preprocessing`** folder.  \n",
    "2. **Optionally** perform consistency checks (ensuring each `.pt` file has the expected dimensions, verifying boundary channels exist if required, etc.).\n",
    "\n",
    "> **Why keep this step separate?**  \n",
    "> Preprocessing is distinct from core transformations because it can be **highly domain-specific** and may evolve over time. For instance, advanced HPC or industrial PDE pipelines might integrate strict validation rules (e.g., confirming mesh connectivity, verifying boundary compliance).\n",
    "\n",
    "> **Extending Preprocessing**  \n",
    "> In a **production** setup, you might expand this step to automate the following:\n",
    "> - **`PREPROC_REMOVE_OUTLIERS`** and **`PREPROC_DETECT_REPLACE_NANS`** to ensure data integrity.  \n",
    "> - **`PREPROC_LOG_STATS`** to capture summarizing metrics in a QA/QC log.  \n",
    "> - **`PREPROC_ADD_BOUNDARY_LABELS`** to incorporate more sophisticated geometry masks.  \n",
    "> - **Integration** with anomaly detection networks to flag suspicious samples or **retain** high-value domain extremes.\n",
    "\n",
    "For now, our function (`do_preprocessing_for_candidates`) remains a **placeholder** indicating where these operations would occur. Future versions can expand domain-specific logic as needed, ensuring each candidate’s data is **validated**, **cleaned**, and **augmented** prior to **FeaturePreparation** or final model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidate0': {'model_name': 'FNOWithDropout',\n",
       "  'plan': {'candidate0': {'model_name': 'FNOWithDropout',\n",
       "    'plan': {'model_name': 'FNOWithDropout',\n",
       "     'stages': [{'stage_name': '01_01_01_LoadRawData',\n",
       "       'transform_ops': [{'method': 'copy_only',\n",
       "         'params': {'source_folder': '00_Generate_Data',\n",
       "          'dest_folder': '01_01_LoadRawData',\n",
       "          'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]},\n",
       "      {'stage_name': '01_01_03_TransformRawData',\n",
       "       'transform_ops': [{'method': 'copy_only',\n",
       "         'params': {'source_folder': '01_01_LoadRawData',\n",
       "          'dest_folder': '01_01_03_TransformRawData',\n",
       "          'subfolder_source': 'candidate0',\n",
       "          'subfolder_dest': 'candidate0',\n",
       "          'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]},\n",
       "      {'stage_name': '01_01_04_Preprocessing',\n",
       "       'transform_ops': [{'method': 'copy_only',\n",
       "         'params': {'source_folder': '01_01_03_TransformRawData',\n",
       "          'dest_folder': '01_01_04_Preprocessing',\n",
       "          'subfolder_source': 'candidate0',\n",
       "          'subfolder_dest': 'candidate0',\n",
       "          'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]},\n",
       "      {'stage_name': '01_01_05_FeaturePreparation',\n",
       "       'transform_ops': [{'method': 'copy_only',\n",
       "         'params': {'source_folder': '01_01_04_Preprocessing',\n",
       "          'dest_folder': '01_01_05_FeaturePreparation',\n",
       "          'subfolder_source': 'candidate0',\n",
       "          'subfolder_dest': 'candidate0',\n",
       "          'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}]}},\n",
       "   'candidate1': {'model_name': 'AFNO',\n",
       "    'plan': {'model_name': 'AFNO',\n",
       "     'stages': [{'stage_name': '01_01_01_LoadRawData',\n",
       "       'transform_ops': [{'method': 'copy_only',\n",
       "         'params': {'source_folder': '00_Generate_Data',\n",
       "          'dest_folder': '01_01_LoadRawData',\n",
       "          'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]},\n",
       "      {'stage_name': '01_01_03_TransformRawData',\n",
       "       'transform_ops': [{'method': 'copy_only',\n",
       "         'params': {'source_folder': '01_01_LoadRawData',\n",
       "          'dest_folder': '01_01_03_TransformRawData',\n",
       "          'subfolder_source': 'candidate1',\n",
       "          'subfolder_dest': 'candidate1',\n",
       "          'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]},\n",
       "      {'stage_name': '01_01_04_Preprocessing',\n",
       "       'transform_ops': [{'method': 'copy_only',\n",
       "         'params': {'source_folder': '01_01_03_TransformRawData',\n",
       "          'dest_folder': '01_01_04_Preprocessing',\n",
       "          'subfolder_source': 'candidate1',\n",
       "          'subfolder_dest': 'candidate1',\n",
       "          'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]},\n",
       "      {'stage_name': '01_01_05_FeaturePreparation',\n",
       "       'transform_ops': [{'method': 'copy_only',\n",
       "         'params': {'source_folder': '01_01_04_Preprocessing',\n",
       "          'dest_folder': '01_01_05_FeaturePreparation',\n",
       "          'subfolder_source': 'candidate1',\n",
       "          'subfolder_dest': 'candidate1',\n",
       "          'data_dir_path': 'examples/cfd/darcy_autoML_active_learning/data'}}]}]}}}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Preprocessing] Loaded transformation plans from examples/cfd/darcy_autoML_active_learning/data/01_01_DataTransformationPlan/transformation_plans.json.\n",
      "Candidate keys found: ['candidate0']\n",
      "\n",
      "[Preprocessing] Processing candidate 'candidate0' for model 'FNOWithDropout'\n",
      "    -> No '01_01_04_Preprocessing' stage found for candidate 'candidate0'. Skipping.\n",
      "\n",
      "[Preprocessing] All candidates processed for stage '01_01_04_Preprocessing'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from darcy_automl_active_learning.ontology.ontology_transformation_engine import OntologyTransformationEngine\n",
    "\n",
    "# 1) Path to the transformation plans\n",
    "plans_json_path = os.path.join(data_dir_path, \"01_01_DataTransformationPlan\", \"transformation_plans.json\")\n",
    "if not os.path.exists(plans_json_path):\n",
    "    raise FileNotFoundError(f\"[Preprocessing] Cannot find transformation plans at {plans_json_path}\")\n",
    "\n",
    "# 2) Load the transformation plans\n",
    "with open(plans_json_path, \"r\") as f:\n",
    "    all_candidates_plans = json.load(f)\n",
    "\n",
    "print(f\"[Preprocessing] Loaded transformation plans from {plans_json_path}.\")\n",
    "print(\"Candidate keys found:\", list(all_candidates_plans.keys()))\n",
    "\n",
    "# 3) Instantiate or reuse the transformation engine\n",
    "trans_engine = OntologyTransformationEngine()\n",
    "\n",
    "# We'll assume the source folder is \"01_01_03_TransformRawData\"\n",
    "source_root = os.path.join(data_dir_path, \"01_01_03_TransformRawData\")\n",
    "\n",
    "# 4) For each candidate, find the stage \"01_01_04_Preprocessing\" and execute\n",
    "for candidate_key, plan_info in all_candidates_plans.items():\n",
    "\n",
    "    model_name = plan_info[\"model_name\"]\n",
    "    plan_dict  = plan_info[\"plan\"]\n",
    "\n",
    "    print(f\"\\n[Preprocessing] Processing candidate '{candidate_key}' for model '{model_name}'\")\n",
    "\n",
    "    # 4a) Retrieve the list of stages\n",
    "    stages = plan_dict.get(\"stages\", [])\n",
    "\n",
    "    # 4b) Look for \"01_01_04_Preprocessing\"\n",
    "    preprocessing_stage = next(\n",
    "        (st for st in stages if st.get(\"stage_name\") == \"01_01_04_Preprocessing\"),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if preprocessing_stage is None:\n",
    "        print(f\"    -> No '01_01_04_Preprocessing' stage found for candidate '{candidate_key}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 4c) Retrieve transform_ops\n",
    "    transform_ops = preprocessing_stage.get(\"transform_ops\", [])\n",
    "    if not transform_ops:\n",
    "        print(f\"    -> '01_01_04_Preprocessing' has no transform_ops for '{candidate_key}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 4d) Create the destination folder\n",
    "    dest_folder = os.path.join(data_dir_path, \"01_01_04_Preprocessing\", candidate_key)\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "    # 4e) Execute each transform method\n",
    "    for op in transform_ops:\n",
    "        method_name = op[\"method\"]\n",
    "        params      = op[\"params\"]\n",
    "\n",
    "        # Override the source/dest for clarity (common pattern in your pipeline)\n",
    "        params[\"source_folder\"] = os.path.join(source_root, candidate_key)\n",
    "        params[\"dest_folder\"]   = dest_folder\n",
    "\n",
    "        print(f\"    -> Invoking '{method_name}' with params: {params}\")\n",
    "\n",
    "        if hasattr(trans_engine, method_name):\n",
    "            method = getattr(trans_engine, method_name)\n",
    "            method(**params)\n",
    "        else:\n",
    "            print(f\"    -> [Warning] Method '{method_name}' not found in transformation engine. Skipped.\")\n",
    "\n",
    "    print(f\"    -> Finished preprocessing for candidate '{candidate_key}'.\")\n",
    "\n",
    "print(\"\\n[Preprocessing] All candidates processed for stage '01_01_04_Preprocessing'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### 01_01_05 FeaturePreparation\n",
    "\n",
    "Even with **preprocessing** in place, many **PDE workflows** can benefit from **feature engineering** to give models the best possible representation of the domain. Such feature engineering often targets **input** channels or **auxiliary** data that helps the model learn PDE patterns more effectively. Typical operations may include:\n",
    "\n",
    "- **Boundary Channel Additions**  \n",
    "  - **`FEATURE_ADD_BOUNDARY_MASK`**: Creating a channel that flags boundary nodes or cells (e.g., 1 at boundary, 0 in the interior). This clarifies region distinctions for the model.  \n",
    "  - **`FEATURE_MESH_ADJ_INFO`**: For mesh-based PDEs, encoding adjacency or connectivity in a way that the model can leverage more directly.\n",
    "\n",
    "- **Coordinate Expansions**  \n",
    "  - **`FEATURE_ADD_COORDS`**: Injecting explicit \\((x, y)\\) or \\((x, y, z)\\) coordinates into each data sample if they’re not already included.  \n",
    "  - **`FEATURE_TRANSFORM_COORDS`**: Converting from Cartesian to polar/spherical coordinates for certain domains or PDE problems.\n",
    "\n",
    "- **Channel Rearrangements & Combinations**  \n",
    "  - **`FEATURE_STACK_INPUTS`**: Stacking multiple PDE fields (e.g., temperature + velocity) into a single input tensor.  \n",
    "  - **`FEATURE_SPLIT_FIELDS`**: Splitting one multi-channel input into separate sub-tensors for specialized architectures.\n",
    "\n",
    "- **Scaling or Normalizing Fields**  \n",
    "  - **`FEATURE_SCALE_CHANNELS`**: Applying scaling or normalization to each channel (e.g., min–max scaling or standard deviation normalization) after domain-specific preprocessing.  \n",
    "  - **`FEATURE_LOG_TRANSFORM`**: Sometimes used for PDE variables that span multiple magnitudes (e.g., exponential growth in wave amplitude or flow velocity).\n",
    "\n",
    "- **Noise Injection & Data Augmentation**  \n",
    "  - **`FEATURE_ADD_NOISE`**: Introducing mild noise for regularization or simulating measurement uncertainty in sensor-based PDE data.  \n",
    "  - **`FEATURE_AUGMENT_GEOMETRY`**: Additional geometric transformations (e.g., flips, slight domain perturbations) that specifically enhance feature diversity.\n",
    "\n",
    "---\n",
    "\n",
    "**Prototype Implementation**  \n",
    "In our current pipeline, we keep **FeaturePreparation** **minimal**—doing little more than **copying** the data to a new folder. However, this step represents a natural **extension point** for domain-specific feature engineering. We envision a function `prepare_features_for_candidates(...)` in **`src/feature_engineering.py`** that could eventually:\n",
    "\n",
    "1. **Verify** the presence of core PDE channels (e.g., `permeability`, `pressure`, `velocity`).  \n",
    "2. **Combine** or **split** channels as needed for a given architecture (e.g., wavelet vs. graph-based).  \n",
    "3. **Inject** boundary masks or coordinate arrays if a model demands explicit domain context.\n",
    "\n",
    "By **decoupling** this from the earlier **Preprocessing** (which focuses on data cleaning and consistency), we ensure that model-specific or domain-specific feature engineering can **evolve** independently. Over time, additional transformations (like **`FEATURE_ADD_COORDS`**, **`FEATURE_SPLIT_FIELDS`**, or **`FEATURE_LOG_TRANSFORM`**) can be integrated without disrupting the rest of the pipeline. As a result, each candidate model can have precisely the **feature representation** it needs to learn effectively from the PDE data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FeaturePreparation] Loaded transformation plans from examples/cfd/darcy_autoML_active_learning/data/01_01_DataTransformationPlan/transformation_plans.json.\n",
      "Candidate keys found: ['candidate0']\n",
      "\n",
      "[FeaturePreparation] Processing candidate 'candidate0' for model 'FNOWithDropout'\n",
      "    -> No '01_01_05_FeaturePreparation' stage found for candidate 'candidate0'. Skipping.\n",
      "\n",
      "[FeaturePreparation] All candidates processed for stage '01_01_05_FeaturePreparation'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from darcy_automl_active_learning.ontology.ontology_transformation_engine import OntologyTransformationEngine\n",
    "\n",
    "# 1) Path to the transformation plans\n",
    "plans_json_path = os.path.join(data_dir_path, \"01_01_DataTransformationPlan\", \"transformation_plans.json\")\n",
    "if not os.path.exists(plans_json_path):\n",
    "    raise FileNotFoundError(f\"[FeaturePreparation] Cannot find transformation plans at {plans_json_path}\")\n",
    "\n",
    "# 2) Load the transformation plans\n",
    "with open(plans_json_path, \"r\") as f:\n",
    "    all_candidates_plans = json.load(f)\n",
    "\n",
    "print(f\"[FeaturePreparation] Loaded transformation plans from {plans_json_path}.\")\n",
    "print(\"Candidate keys found:\", list(all_candidates_plans.keys()))\n",
    "\n",
    "# 3) Instantiate (or reuse) the transformation engine\n",
    "trans_engine = OntologyTransformationEngine()\n",
    "\n",
    "# We'll assume the source folder is \"01_01_04_Preprocessing\"\n",
    "source_root = os.path.join(data_dir_path, \"01_01_04_Preprocessing\")\n",
    "\n",
    "# 4) For each candidate, look for the stage \"01_01_05_FeaturePreparation\" and execute\n",
    "for candidate_key, plan_info in all_candidates_plans.items():\n",
    "    # plan_info typically looks like:\n",
    "    # {\n",
    "    #   \"model_name\": \"FNOWithDropout\",\n",
    "    #   \"plan\": {\n",
    "    #       \"model_name\": \"FNOWithDropout\",\n",
    "    #       \"stages\": [\n",
    "    #         {\n",
    "    #           \"stage_name\": \"01_01_01_LoadRawData\",\n",
    "    #           \"transform_ops\": [...]\n",
    "    #         },\n",
    "    #         {\n",
    "    #           \"stage_name\": \"01_01_05_FeaturePreparation\",\n",
    "    #           \"transform_ops\": [...]\n",
    "    #         },\n",
    "    #         ...\n",
    "    #       ]\n",
    "    #   }\n",
    "    # }\n",
    "\n",
    "    model_name = plan_info[\"model_name\"]\n",
    "    plan_dict = plan_info[\"plan\"]\n",
    "\n",
    "    print(f\"\\n[FeaturePreparation] Processing candidate '{candidate_key}' for model '{model_name}'\")\n",
    "\n",
    "    # 4a) Retrieve the list of stages\n",
    "    stages = plan_dict.get(\"stages\", [])\n",
    "\n",
    "    # 4b) Find the \"01_01_05_FeaturePreparation\" stage\n",
    "    featureprep_stage = next(\n",
    "        (st for st in stages if st.get(\"stage_name\") == \"01_01_05_FeaturePreparation\"),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if featureprep_stage is None:\n",
    "        print(f\"    -> No '01_01_05_FeaturePreparation' stage found for candidate '{candidate_key}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 4c) Retrieve transform_ops\n",
    "    transform_ops = featureprep_stage.get(\"transform_ops\", [])\n",
    "    if not transform_ops:\n",
    "        print(f\"    -> '01_01_05_FeaturePreparation' has no transform_ops for '{candidate_key}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 4d) Create the destination folder\n",
    "    dest_folder = os.path.join(data_dir_path, \"01_01_05_FeaturePreparation\", candidate_key)\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "    # 4e) Execute each transformation operation\n",
    "    for op in transform_ops:\n",
    "        method_name = op[\"method\"]\n",
    "        params = op[\"params\"]\n",
    "\n",
    "        # Override the source/dest for clarity\n",
    "        params[\"source_folder\"] = os.path.join(source_root, candidate_key)\n",
    "        params[\"dest_folder\"]   = dest_folder\n",
    "\n",
    "        print(f\"    -> Invoking '{method_name}' with params: {params}\")\n",
    "\n",
    "        if hasattr(trans_engine, method_name):\n",
    "            method = getattr(trans_engine, method_name)\n",
    "            method(**params)\n",
    "        else:\n",
    "            print(f\"    -> [Warning] Method '{method_name}' not found in transform engine. Skipped.\")\n",
    "\n",
    "    print(f\"    -> Finished feature preparation for candidate '{candidate_key}'.\")\n",
    "\n",
    "print(\"\\n[FeaturePreparation] All candidates processed for stage '01_01_05_FeaturePreparation'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Conclusion: Data Pipeline Ready\n",
    "\n",
    "We have successfully completed an **end-to-end data pipeline** for our Darcy Flow (or more generally PDE-based) project, incorporating:\n",
    "\n",
    "1. **Data Descriptor & Model Compatibility**\n",
    "   - Defined a **comprehensive data descriptor** (`data_desc.json`) capturing dimension, geometry type, uniformity, and more.\n",
    "   - Used a `ModelRegistry` and a simple `AutoMLCandidateModelSelection` to verify which candidate models (e.g., FNO, AFNO) can directly consume our dataset, or if transformations are required.\n",
    "\n",
    "2. **Raw Data Loading (`01_01_LoadRawData`)**\n",
    "   - Copied raw `.pt` files from `data/00_Generate_Data` to `data/01_01_LoadRawData`.\n",
    "   - Preserved the data descriptor for consistency.\n",
    "   - Performed minimal Exploratory Data Analysis (EDA) to confirm file integrity and shapes (e.g., checking `\"permeability\"`, `\"darcy\"`).\n",
    "\n",
    "3. **Transforming Raw Data (`01_01_03_TransformRawData`)**\n",
    "   - For each **candidate model** (e.g., `candidate0`, `candidate1`), created a dedicated subfolder in `data/01_03_TransformRawData`.\n",
    "   - Demonstrated how to handle **typical PDE transformations**:\n",
    "     - **`TRANSFORM_MESH_TO_GRID`**: Converting an unstructured mesh to a uniform grid if required by a spectral-based operator.\n",
    "     - **`TRANSFORM_DECIMATE_MESH`**: Reducing mesh complexity for memory or performance constraints.\n",
    "     - **`TRANSFORM_REGRID_DATA`**: Adjusting resolution or coordinate spacing to match model expectations.\n",
    "     - **`TRANSFORM_APPLY_BC_AUGMENTATION`**: Incorporating boundary-condition channels (if not added earlier).\n",
    "     - **`TRANSFORM_NORMALIZE`**: Standardizing or normalizing PDE fields (e.g., substract mean, divide by std).\n",
    "   - Kept transformations minimal in this prototype, but laid out the structure for more sophisticated re-gridding or domain modifications if needed.\n",
    "\n",
    "4. **Preprocessing (`01_01_04_Preprocessing`)**\n",
    "   - Introduced a **placeholder** for additional PDE data modifications, including:\n",
    "     - **`PREPROC_GEOMETRY_AUGMENT`**: Random rotations, domain cropping, or flips.\n",
    "     - **`PREPROC_REMOVE_OUTLIERS`**: Filtering extreme or invalid values.\n",
    "     - **`PREPROC_DETECT_REPLACE_NANS`**: Handling missing or corrupted data points.\n",
    "     - **`PREPROC_FILTER_INCOMPLETE_SAMPLES`**: Removing partial or malformed data entries.\n",
    "   - Copied the transformed data for each candidate into `data/01_04_Preprocessing`, ensuring any domain- or application-specific cleaning can be done here.\n",
    "\n",
    "5. **Feature Preparation (`01_01_05_FeaturePreparation`)**\n",
    "   - Final stage of data engineering before **model training**, covering potential:\n",
    "     - **Boundary Mask Channels** (e.g., `FEATURE_ADD_BOUNDARY_MASK`).\n",
    "     - **Coordinate Expansions** (`FEATURE_ADD_COORDS`), if needed for operator-based PDE solvers.\n",
    "     - **Channel Stacking** (`FEATURE_STACK_INPUTS`) or **Splitting** (`FEATURE_SPLIT_FIELDS`) to reorganize PDE fields.\n",
    "     - **Scaling** or **Augmentation** for the final inputs (e.g., `FEATURE_SCALE_CHANNELS` or `FEATURE_ADD_NOISE`).\n",
    "   - Copied or updated files under `data/01_05_FeaturePreparation`, providing a flexible hook for advanced PDE-specific feature engineering.\n",
    "\n",
    "**Outcome & Next Steps**  \n",
    "All data are now **cleaned**, **transformed**, and **feature-engineered** in a structured manner, ready for **surrogate model training** or **AutoML** hyperparameter tuning. Our project’s data folders now look like:\n",
    "\n",
    "```\n",
    "data/\n",
    " ├─ 00_Generate_Data/\n",
    " │    └─ data_desc.json\n",
    " ├─ 01_00_AutoMLCandidateModelSelection/\n",
    " │    └─ chosen_candidates.json\n",
    " ├─ 01_01_LoadRawData/\n",
    " ├─ 01_03_TransformRawData/\n",
    " │    ├─ candidate0/\n",
    " │    └─ candidate1/\n",
    " ├─ 01_04_Preprocessing/\n",
    " │    ├─ candidate0/\n",
    " │    └─ candidate1/\n",
    " └─ 01_05_FeaturePreparation/\n",
    "      ├─ candidate0/\n",
    "      └─ candidate1/\n",
    "```\n",
    "\n",
    "With the **data pipeline** complete, we can move on to **model definition**, **training**, and (optionally) **AutoML** tasks such as hyperparameter optimization or multi-model experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 01_02 Model Definition\n",
    "\n",
    "In this section, we introduce our primary PDE surrogate model definitions. We focus on two main variants:\n",
    "\n",
    "1. **FNOWithDropout** – A custom subclass of Modulus’s Fourier Neural Operator (FNO) that injects dropout. This allows us to do Monte Carlo Dropout–based uncertainty estimation or simply add a regularization mechanism.\n",
    "2. **AFNO** – NVIDIA Modulus’s Adaptive Fourier Neural Operator, which uses an adaptive frequency gating approach for improved spectral flexibility.\n",
    "\n",
    "Both surrogates rely on hyperparameter definitions stored in our `config.yaml` under `cfg.arch.fno.*` or `cfg.arch.afno.*`. By default, we’ll pull settings like `in_channels`, `out_channels`, `latent_channels`, `drop` (dropout rate), and so on directly from `config.yaml`. You can override these values in the notebook if needed—just edit the `cfg` object before creating the models.\n",
    "\n",
    "We’ll keep the actual model classes (and any helper functions) in `src/models.py` (or sub-files like `fno_dropout.py`, `afno.py`), each thoroughly documented with docstrings. Then, in the next cells, we’ll show how to use these classes in conjunction with the config fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 01_03 Model Factory\n",
    "\n",
    "This section focuses on **merging our user configuration** (especially the field `cfg.model_name`) with the model definitions created in “01_02 Model Definition.” By doing so, we can **automate** which PDE surrogate to build—be it an FNO-based model, AFNO, or a future extension (like a PINN or DiffusionNet). \n",
    "\n",
    "**Why a Factory?** It lets us keep a **single** entry point (`get_model(cfg)`), which reads the relevant parameters (`cfg.arch.fno.*`, `cfg.arch.afno.*`, etc.) and returns the correct PyTorch module. This modular approach also makes it straightforward to **add** new model variants (e.g., a different neural operator) without changing the notebook workflow. \n",
    "\n",
    "In the following steps, we’ll:\n",
    "1. Create a new file, `model_factory.py`, that defines `get_model(cfg)` (with docstrings).\n",
    "2. Demonstrate how we **import** and **use** this factory function in the notebook.\n",
    "3. Confirm it works by instantiating a model and optionally running a quick shape check.\n",
    "\n",
    "This pattern helps maintain a **clean separation** between model definitions and the logic that decides **which** model to instantiate—making the pipeline easier to scale and adapt for new PDE surrogates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 01_04 Configuring Hyperparameters\n",
    "\n",
    "In this section, we outline how to configure the hyperparameters for our PDE surrogate models. \n",
    "Recall that we store default values (like `epochs`, `learning_rate`, `batch_size`, etc.) in our\n",
    "[`config.yaml`](./config.yaml). \n",
    "\n",
    "For instance, here are a few default hyperparameters you might see in that file:\n",
    "\n",
    "| Hyperparameter      | Default Value | Description / Notes                                |\n",
    "|---------------------|--------------|-----------------------------------------------------|\n",
    "| `training.epochs`   | 10           | Number of training epochs                           |\n",
    "| `training.lr`       | 1e-3         | Initial learning rate for the optimizer            |\n",
    "| `training.batch_size` | 16        | Mini-batch size for training loops                 |\n",
    "| `arch.fno.num_fno_modes` | 12      | Number of Fourier modes (FNO-specific)             |\n",
    "| `arch.afno.drop`    | 0.1          | Dropout rate for AFNO gating (AFNO-specific)       |\n",
    "\n",
    "**Overriding Hyperparams Locally**  \n",
    "You can update these hyperparameters within the notebook before training or tuning. For example:\n",
    "```python\n",
    "cfg.training.lr = 5e-4\n",
    "cfg.training.epochs = 30\n",
    "print(\"Updated training config:\", cfg.training)\n",
    "```\n",
    "\n",
    "**Using MLFlow**  \n",
    "We also demonstrate how to log hyperparameters to MLFlow, so each run’s configuration is \n",
    "stored alongside its metrics and artifacts. In a typical flow, you might do:\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "mlflow.start_run(run_name=\"Experiment_FNO\")\n",
    "# log hyperparams\n",
    "log_hyperparams_mlflow(cfg)\n",
    "\n",
    "# proceed with training...\n",
    "mlflow.end_run()\n",
    "```\n",
    "\n",
    "In subsequent cells, we’ll show how to integrate these hyperparameters into the training loop, \n",
    "as well as how to override them for AutoML or HPC use cases if you wish. \n",
    "This approach ensures a **reproducible** pipeline—where each run can be traced back \n",
    "to its exact configuration and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 01_05 Model Training Loop\n",
    "\n",
    "In this section, we implement a **generic PDE training loop** that references our **configuration parameters** (like epochs, learning rate, batch size, etc.) from `config.yaml`. This training loop can be used for:\n",
    "\n",
    "- **Single-Run Training**: Train a single model with a chosen set of hyperparameters (e.g., an FNO or AFNO).\n",
    "- **Multi-Run/AutoML** scenarios: Called multiple times with different hyperparameter overrides for hyperparameter tuning (we’ll see this usage in a later section).\n",
    "\n",
    "We incorporate:\n",
    "- **Progress Bars** with `tqdm`, to get live feedback on training progress (especially helpful in notebooks).\n",
    "- **MLFlow Logging** (optional), so each epoch’s train and validation loss is recorded for future analysis.\n",
    "- **Device Handling** (CPU vs. GPU via a `device` parameter).\n",
    "\n",
    "If you’re running on **HPC or distributed** environments, you may want to disable the tqdm progress bars (for performance/logging reasons) and/or integrate distributed managers from Modulus or PyTorch. We’ll point out where those hooks go, but keep them minimal for this prototype.\n",
    "\n",
    "Below, we’ll demonstrate how to use our training loop, pass in a config object, and see the relevant progress bar and MLFlow logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 01_06 Model Training Execution\n",
    "\n",
    "In this section, we bring together all of the moving parts from our pipeline:\n",
    "- **Data pipeline**: The raw data has been generated, transformed, and preprocessed in the earlier steps.\n",
    "- **Model factory**: We can instantiate our chosen model (e.g., FNO or AFNO) using the config-based logic from “01_03 Model Factory.”\n",
    "- **Hyperparameter settings**: From “01_04 Configuring Hyperparameters,” we have default (or overridden) values for epochs, learning rate, batch size, and so on.\n",
    "- **Training loop**: As defined in “01_05 Model Training Loop,” which handles epochs, mini-batches, loss calculation, optional validation, and more.\n",
    "\n",
    "By **combining** these steps, we now present a **user-facing script or function** (`execute_training` or similar) that performs the **end-to-end** training process:\n",
    "1. **Pull** the final data loader(s),  \n",
    "2. **Create** or load the model,  \n",
    "3. **Train** using our training loop,  \n",
    "4. **Track** progress in a notebook progress bar (using `tqdm` by default),  \n",
    "5. **Log** metrics to MLFlow (if desired),  \n",
    "6. **Save** checkpoints according to the user’s preference (final, best, or every epoch).\n",
    "\n",
    "We’ll also briefly show how to adjust or disable certain features for HPC usage—such as turning off the progress bar or hooking in distributed training if needed. The remainder of this section walks through a Python function and example usage in the notebook to carry out this consolidated training flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 01_07 AutoML and Hyperparameter Tuning\n",
    "In the previous section (“01_06 Model Training Execution”), we demonstrated how to train our PDE surrogate (FNO or AFNO) with a chosen set of hyperparameters—either from our default `config.yaml` or via simple overrides. Now, we turn to a more **systematic** approach: **hyperparameter tuning** or **AutoML**.\n",
    "\n",
    "Here, we’ll leverage a search method (grid, random, or Bayesian—commonly **Optuna** in Python) to explore the hyperparameter space. Our `config.yaml` already contains default parameter values and additional fields (under `cfg.automl`) specifying **ranges** (e.g., Fourier modes from 8 to 20, learning rate from 1e-4 to 5e-3, etc.). \n",
    "\n",
    "**MLFlow Logging**  \n",
    "Just as in our normal training, we’ll integrate MLFlow to log each hyperparam trial’s configuration and final metrics. By doing so, we can easily compare many trials in a single, consolidated UI. \n",
    "\n",
    "**Progress Bars**  \n",
    "For each trial, we can still rely on our PDE training loop’s `tqdm` progress bar—although for a large number of trials, it might be practical to reduce the training epochs or batch sizes to speed up each run.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Points in This Section**\n",
    "1. **Hyperparameter Range Setup**  \n",
    "   We confirm or update the `config.yaml` sub-tree (`cfg.automl`) that defines the search space for FNO (e.g. `modes`, `width`, `depth`, etc.) and, if relevant, for AFNO (`drop`, `gating_strength`, etc.).\n",
    "\n",
    "2. **AutoML Logic**  \n",
    "   We’ll create or review a new file, `src/automl.py`, which contains code to parse those search ranges and define an **Optuna objective** function.\n",
    "\n",
    "3. **Partial vs. Full Training**  \n",
    "   In each trial, we might do a reduced set of epochs or data to expedite the search. Once the best params are found, we’ll do a **full** retraining using the discovered configuration.\n",
    "\n",
    "4. **MLFlow**  \n",
    "   We’ll log each trial’s hyperparams and final validation metrics under separate nested runs, so you can open MLFlow and compare them.\n",
    "\n",
    "By the end of this section, you’ll have seen how to run multiple hyperparam search trials—**automatically** adjusting FNO or AFNO parameters—before picking the best discovered setup for a final training pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 01_08 Visualizing Performance and Results\n",
    "\n",
    "After training our PDE surrogate models (and possibly using AutoML to tune hyperparameters),\n",
    "we now want to **examine** how well they perform. In this section, we will:\n",
    "\n",
    "1. **Load** the training/validation metrics from our logs (or MLFlow, if enabled).\n",
    "2. **Plot** these metrics (e.g., loss curves over epochs).\n",
    "3. **Compare** model predictions to ground-truth solutions for a few test samples—especially\n",
    "   valuable in Darcy flow, where we can visualize the predicted pressure fields vs. the true\n",
    "   solution.\n",
    "4. **Summarize** errors (e.g., MSE, absolute difference) across a set of test samples to\n",
    "   get a sense of overall accuracy, variance, and potential failure cases.\n",
    "\n",
    "We rely on the utility functions we placed in **`src/visualization.py`**:\n",
    "\n",
    "- `plot_train_val_loss(...)`: For plotting training/validation loss curves.\n",
    "- `plot_prediction_comparison(...)`: Side-by-side visualization of **input** (permeability),\n",
    "  **predicted** (pressure), **ground truth** (pressure), and a simple **error map**.\n",
    "- `plot_error_distribution(...)`: Quick histogram or boxplot of errors across many samples.\n",
    "- `summarize_metrics_table(...)`: A small table summarizing results from multiple runs.\n",
    "\n",
    "Finally, we’ll also **load** a saved model checkpoint (if we have one) or pick a final/best-epoch\n",
    "checkpoint to run inference on sample PDE inputs. By the end, we should have a clear picture\n",
    "of how our model is performing and any areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Concluding the Visualization & Pipeline\n",
    "We’ve now completed a full pass through our PDE surrogate pipeline—from data preparation, \n",
    "model definition, and hyperparameter tuning, to final training and results visualization.\n",
    "\n",
    "- **Final Observations**:  \n",
    "  - For instance, using FNO with `modes=12` and `width=64` yielded approximately **X%** relative error on the test set.  \n",
    "  - The predicted Darcy fields show close alignment with the ground truth solutions, as seen in our 2D plots.\n",
    "\n",
    "- **HPC Readiness**:  \n",
    "  - If you plan to run larger resolutions or more epochs, the same notebook logic can scale to HPC environments. \n",
    "  - You may disable the progress bar or use a distributed manager (e.g., `DistributedManager` in Modulus) to parallelize training.\n",
    "\n",
    "- **Advanced Features**:  \n",
    "  - In real-world scenarios, consider adding PDE constraints, subgrid modeling, or multi-objective optimization if the use-case demands more advanced physics fidelity.\n",
    "  - **Active Learning** can be integrated to select new PDE samples, especially if generating or simulating data is expensive.\n",
    "\n",
    "- **MLFlow or Other Logs**:  \n",
    "  - If you recorded metrics in MLFlow, open the MLFlow UI (or your logging interface) to view interactive charts, parameter comparisons, and artifacts (e.g., model checkpoints, images).\n",
    "\n",
    "**Next Steps**:\n",
    "1. **Refine the Model**: Increase epochs, tweak hyperparameters further, or incorporate additional PDE constraints.\n",
    "2. **Deploy or Save** the pipeline: Convert your final model to an inference engine or HPC environment.\n",
    "3. **Explore** expansions like deeper AFNO gating, multi-physics PDE coupling, or more advanced domain transformations.\n",
    "\n",
    "With these steps, you have a **functioning** pipeline that can be adapted for **larger HPC** usage, \n",
    "more sophisticated PDE tasks, or integrated with **AutoML** strategies to systematically refine hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
